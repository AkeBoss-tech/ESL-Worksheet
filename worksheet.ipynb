{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from util import generate_fill_worksheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "couple/file-2.txt\n",
      "level/file-6-71.txt\n",
      "level/file-6-89.txt\n",
      "couple/file-17.txt\n",
      "people/file-20.txt\n",
      "essays/file-3.txt\n",
      "essays/file-50.txt\n",
      "essays/file-49.txt\n",
      "customs/file-51.txt\n",
      "essays/file-18.txt\n",
      "level/file-5-99.txt\n",
      "essays/file-3.txt\n",
      "customs/file-93.txt\n",
      "people/file-11.txt\n",
      "couple/file-21.txt\n",
      "couple/file-44.txt\n",
      "people/file-67.txt\n",
      "people/file-64.txt\n",
      "level/file-3-99.txt\n",
      "people/file-83.txt\n",
      "essays/file-86.txt\n",
      "essays/file-45.txt\n",
      "people/file-10.txt\n",
      "couple/file-52.txt\n",
      "couple/file-14.txt\n",
      "essays/file-77.txt\n",
      "couple/file-28.txt\n",
      "customs/file-13.txt\n",
      "people/file-57.txt\n",
      "level/file-4-86.txt\n",
      "\tFill in the Verb\n",
      "\n",
      "1. I _____ you should drop out of the Homecoming race. (to think)\n",
      "2. Voice ________ happens to everyone. (to crack)\n",
      "3. He ___ coughing and sneezing at work. (to be)\n",
      "4. It ________ the president of the United States, the vice-president, and the cabinet. (to include)\n",
      "5. His myth states that he _______ fire to the world. (to bring)\n",
      "6. It is located on Liberty Island _____ off the southern tip of Manhattan, New York City. (to right)\n",
      "7. A part of the avenue ________ expensive designer stores like Tiffany's. (to feature)\n",
      "8. The winner of the sweepstakes ___ going to be announced on the Herrio Cereal website. (to be)\n",
      "9. In 1993 the first of several people ____ forward to accuse Jackson of sexually improper conduct on a child. (to come)\n",
      "10. Mike ______ on the television. (to turn)\n",
      "11. Mary and Maria ___ attended high school together. (to have)\n",
      "12. This site at Stanford would ______ to the Google search engine today. (to evolve)\n",
      "13. She also ______ for Stride Rite, and Hasbro Corporations. (to work)\n",
      "14. Some people _____ the rise of helicopter parenting on the rise of cell phones. (to blame)\n",
      "15. He ___ voted Forbes Magazine's Most Influential Celebrity in America in 2014. (to be)\n",
      "16. Little by little, they ______ the theater. (to exit)\n",
      "17. In the times before the invention of the personal computer, and the advent of the World Wide Web, social networking ___ done in person. (to be)\n",
      "18. Volunteers _____ U.S. (to place)\n",
      "19. In 1920, she ______ found the American Civil Liberties Union, which is still active today. (to help)\n",
      "20. They ______. (to talk)\n",
      "\n",
      "\n",
      "\tAnswer Key\n",
      "\n",
      "1. think\n",
      "2. cracking\n",
      "3. was\n",
      "4. includes\n",
      "5. brought\n",
      "6. right\n",
      "7. features\n",
      "8. was\n",
      "9. came\n",
      "10. turned\n",
      "11. had\n",
      "12. evolve\n",
      "13. worked\n",
      "14. blame\n",
      "15. was\n",
      "16. exited\n",
      "17. was\n",
      "18. place\n",
      "19. helped\n",
      "20. talked\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\tFill in the Verb\\n\\n1. I _____ you should drop out of the Homecoming race. (to think)\\n2. Voice ________ happens to everyone. (to crack)\\n3. He ___ coughing and sneezing at work. (to be)\\n4. It ________ the president of the United States, the vice-president, and the cabinet. (to include)\\n5. His myth states that he _______ fire to the world. (to bring)\\n6. It is located on Liberty Island _____ off the southern tip of Manhattan, New York City. (to right)\\n7. A part of the avenue ________ expensive designer stores like Tiffany's. (to feature)\\n8. The winner of the sweepstakes ___ going to be announced on the Herrio Cereal website. (to be)\\n9. In 1993 the first of several people ____ forward to accuse Jackson of sexually improper conduct on a child. (to come)\\n10. Mike ______ on the television. (to turn)\\n11. Mary and Maria ___ attended high school together. (to have)\\n12. This site at Stanford would ______ to the Google search engine today. (to evolve)\\n13. She also ______ for Stride Rite, and Hasbro Corporations. (to work)\\n14. Some people _____ the rise of helicopter parenting on the rise of cell phones. (to blame)\\n15. He ___ voted Forbes Magazine's Most Influential Celebrity in America in 2014. (to be)\\n16. Little by little, they ______ the theater. (to exit)\\n17. In the times before the invention of the personal computer, and the advent of the World Wide Web, social networking ___ done in person. (to be)\\n18. Volunteers _____ U.S. (to place)\\n19. In 1920, she ______ found the American Civil Liberties Union, which is still active today. (to help)\\n20. They ______. (to talk)\\n\\n\\n\\tAnswer Key\\n\\n1. think\\n2. cracking\\n3. was\\n4. includes\\n5. brought\\n6. right\\n7. features\\n8. was\\n9. came\\n10. turned\\n11. had\\n12. evolve\\n13. worked\\n14. blame\\n15. was\\n16. exited\\n17. was\\n18. place\\n19. helped\\n20. talked\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_fill_worksheet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from util import is_verb\n",
    "\n",
    "bank = set()\n",
    "\n",
    "# similar_words = wordnet.similar_tos('run')\n",
    "for syn in wordnet.synsets(\"run\"):\n",
    "    if not is_verb(syn.name().split('.')[0]): continue\n",
    "\n",
    "    for lemma in syn.lemmas():\n",
    "        bank.add(lemma.name())\n",
    "\n",
    "bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level/file-1-67.txt\n",
      "['He hears a loud noise. He looks out the window. He sees a motorcycle. It is on the road. It is black and silver. It has two wheels. There is a man on the motorcycle. He wears a helmet. He wears sunglasses. He wears a leather jacket. He is riding the motorcycle. ']\n",
      "1. motorcycle - a motor vehicle with two wheels and a strong frame\n",
      "2. sunglasses - spectacles that are darkened or polarized to protect the eyes from the glare of the sun\n",
      "3. wears - impairment resulting from long use\n",
      "3. helmet - armor plate that protects the head\n",
      "4. hears - perceive (sound) via the auditory sense\n",
      "\tVocabulary Worksheet\n",
      "\n",
      "1. motorcycle\t\t\ta. spectacles that are darkened or polarized to protect the eyes from the glare of the sun\n",
      "2. sunglasses\t\t\tb. armor plate that protects the head\n",
      "3. helmet\t\t\tc. a motor vehicle with two wheels and a strong frame\n",
      "\n",
      "\n",
      "\tAnswer Key\n",
      "\n",
      "1. motorcycle - a motor vehicle with two wheels and a strong frame\n",
      "2. sunglasses - spectacles that are darkened or polarized to protect the eyes from the glare of the sun\n",
      "3. helmet - armor plate that protects the head\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import util\n",
    "# asks for inputs in notebook\n",
    "worksheet = util.generate_vocab_worksheet_interactive()\n",
    "print(worksheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customs/file-28.txt\n",
      "\tVocabulary Worksheet\n",
      "\n",
      "1. english\t\t\ta. a body of students who are taught together\n",
      "2. finishes\t\t\tb. move forward, also in the metaphorical sense\n",
      "3. lunches\t\t\tc. an opening that permits escape or release\n",
      "4. tuitions\t\t\td. coming next after the eleventh and just before the thirteenth in position\n",
      "5. standardized\t\t\te. cause to conform to standard or norm\n",
      "6. u.s.\t\t\tf. the executive and legislative and judicial branches of the federal government of the United States\n",
      "7. diploma\t\t\tg. a fee paid for instruction (especially for higher education)\n",
      "8. completing\t\t\th. a course that the student can select from among alternatives\n",
      "9. textbooks\t\t\ti. a set of questions or exercises evaluating skill or knowledge\n",
      "10. electives\t\t\tj. a midday meal\n",
      "11. exam\t\t\tk. a document certifying the successful completion of a course of study\n",
      "12. specialized\t\t\tl. come or bring to a finish or an end\n",
      "13. graduation\t\t\tm. become more focus on an area of activity or field of study\n",
      "14. grades\t\t\tn. an Indo-European language belonging to the West Germanic branch; the official language of Britain and the United States and most of the commonwealth countries\n",
      "15. advanced\t\t\to. the successful completion of a program of study\n",
      "16. exit\t\t\tp. a book prepared for use in schools or colleges\n",
      "17. united\t\t\tq. a decorative texture or appearance of a surface (or the substance that gives it that appearance)\n",
      "18. 12th\t\t\tr. act in concert or unite in a common purpose or belief\n",
      "19. pass\t\t\ts. (baseball) an advance to first base by a batter who receives four balls\n",
      "\n",
      "\n",
      "\tAnswer Key\n",
      "\n",
      "1. english - an Indo-European language belonging to the West Germanic branch; the official language of Britain and the United States and most of the commonwealth countries\n",
      "2. finishes - a decorative texture or appearance of a surface (or the substance that gives it that appearance)\n",
      "3. lunches - a midday meal\n",
      "4. tuitions - a fee paid for instruction (especially for higher education)\n",
      "5. standardized - cause to conform to standard or norm\n",
      "6. u.s. - the executive and legislative and judicial branches of the federal government of the United States\n",
      "7. diploma - a document certifying the successful completion of a course of study\n",
      "8. completing - come or bring to a finish or an end\n",
      "9. textbooks - a book prepared for use in schools or colleges\n",
      "10. electives - a course that the student can select from among alternatives\n",
      "11. exam - a set of questions or exercises evaluating skill or knowledge\n",
      "12. specialized - become more focus on an area of activity or field of study\n",
      "13. graduation - the successful completion of a program of study\n",
      "14. grades - a body of students who are taught together\n",
      "15. advanced - move forward, also in the metaphorical sense\n",
      "16. exit - an opening that permits escape or release\n",
      "17. united - act in concert or unite in a common purpose or belief\n",
      "18. 12th - coming next after the eleventh and just before the thirteenth in position\n",
      "19. pass - (baseball) an advance to first base by a batter who receives four balls\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import util\n",
    "# doesn't ask for inputs in notebook\n",
    "worksheet = util.generate_vocab_worksheet()\n",
    "print(worksheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level/file-3-17.txt\n",
      "couple/file-60.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people/file-48.txt\n",
      "['signaled']\n",
      "['was']\n",
      "['starred']\n",
      "['was', 'was']\n",
      "['had']\n",
      "['was', 'weighed', 'made']\n",
      "['won', 'was', 'were']\n",
      "['went', 'had']\n",
      "['were']\n",
      "['was']\n",
      "['stopped']\n",
      "['suffered', 'lost']\n",
      "['refused']\n",
      "['spent']\n",
      "['used', 'died']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['It signaled the beginning of a new episode of The Adventures of Superman',\n",
       " 'The 1960s show is just one in a series of shows, plays, movies, and comic books that depict the \"Man of Steel.\" The most iconic actor portraying Superman was Christopher Reeve',\n",
       " 'Reeve starred in four movies during the late 1970s and 80s',\n",
       " 'In the 1978 movie classic Superman, Reeve was cast as the legendary American hero based largely on his physical attributes, although he was an accomplished actor',\n",
       " 'Reeve had the classic Superman look',\n",
       " 'He was 6\\'4\" tall, weighed 215 lbs., with a square jaw, and other manly features that made him perfect for the role',\n",
       " 'The film won critical acclaim, and multiple awards, including a \"Special Achievement Award for Visual Effects.\" One of the selling points for the movie was that the special effects were so good that audience would believe that a man can fly after seeing this film',\n",
       " 'Reeve went on to star in three sequels to the original movie, and had a very solid acting career in several movies after that',\n",
       " 'Tragically, Reeve and his family were hit with a devastating blow on May 27, 1995',\n",
       " 'Reeve was riding his horse through a steeplechase course jumping over obstacles',\n",
       " 'His horse suddenly stopped, throwing Reeve to the ground',\n",
       " 'Reeve suffered shattered vertebrae, and instantly lost the use of his arms and legs',\n",
       " 'Reeve refused to give up',\n",
       " 'He spent the rest of his years advocating for spinal cord injury advancement in treatment and technology',\n",
       " 'He used his celebrity status to help the cause, but sadly, Reeve died at the age of 52 in 2004 due to complications from his injuries']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import util\n",
    "util.get_sentences_with_verb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "essays/file-51.txt\n",
      "level/file-2-97.txt\n",
      "people/file-84.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from util import generate_rearrange_worksheet\n",
    "generate_rearrange_worksheet(num=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "essays/file-28.txt\n",
      "level/file-6-69.txt\n",
      "essays/file-57.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from util import random_story, generate_worksheets_for_verb, generate_vocab_worksheet, generate_rearrange_worksheet\n",
    "story = random_story()\n",
    "full_worksheet = '# Worksheet\\n\\n'\n",
    "for paragraph in story:\n",
    "    full_worksheet += '\\t' + paragraph + '\\n'\n",
    "\n",
    "full_worksheet += '\\n\\n'\n",
    "\n",
    "# add worksheets for two verb types\n",
    "for i in range(5):\n",
    "    full_worksheet += generate_worksheets_for_verb(story, verb_type=i)\n",
    "    full_worksheet += '\\n\\n'\n",
    "\n",
    "# add definition worksheet\n",
    "full_worksheet += generate_vocab_worksheet(story)\n",
    "\n",
    "full_worksheet += generate_rearrange_worksheet(story, num=5)\n",
    "\n",
    "print(full_worksheet)\n",
    "\n",
    "# store it in a file\n",
    "with open('worksheet.md', 'w') as f:\n",
    "    f.write(full_worksheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "essays/file-71.txt\n",
      "people/file-27.txt\n",
      "customs/file-29.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "couple/file-10.txt\n",
      "people/file-7.txt\n",
      "level/file-4-90.txt\n",
      "['The Adam family was going on a road trip. They were driving from California to Utah. They were going to see the Grand Canyon. The family got bored on the ride there. The dad suggested they play music. They played music that the whole family liked. After a while, the mom suggested they play a game. They played the alphabet game. Each person would say an animal that started with a letter of the alphabet like ant, bat, cat, dog, and so on. They changed the topic after they went through the whole alphabet. They did names, places, and people. After that, they just talked about what they would do at Utah. They had fun conversations and laughs. ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import util\n",
    "story = util.random_story()\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph must be a string.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['It was Friday morning.',\n",
       " 'Mike and Maria were getting ready for the day.',\n",
       " 'Maria did not have school, and Mike got the day off from work.',\n",
       " 'They had wanted to go to the amusement park for a while now and were finally going to go today.',\n",
       " 'While Maria made breakfast, Mike was taking a shower.',\n",
       " 'Maria made French toast with bacon and strawberries on the side.',\n",
       " 'When Mike finished showering, he got dressed and joined Maria for breakfast.',\n",
       " '\"This tastes delicious!\" said Mike.',\n",
       " '\"Thanks!\" Maria replied.',\n",
       " 'Mike knew how expensive things can be at an amusement park.',\n",
       " 'He thought it would be a good idea to make lunch to have while there.',\n",
       " 'Mike loved going to amusement parks and sometimes told Maria about them and his experiences.',\n",
       " 'Maria had never been to an amusement park.',\n",
       " \"From hearing about Mike's stories, Maria was both excited and nervous about all the big rides.\",\n",
       " 'They made several sandwiches, a fruit salad, and fruit punch.',\n",
       " 'They also planned to take cookies and extra money in case of any emergencies or expenses.',\n",
       " 'Once they were ready, they headed out the door and drove off towards the amusement park.',\n",
       " 'When arriving, they paid for a parking spot and headed towards the entrance of the amusement park.',\n",
       " 'At the entrance, Mike and Maria paid for their admission tickets, and entered the amusement park.24.',\n",
       " 'Going to the Amusement Park (B) .']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def split_into_sentences(paragraph):\n",
    "    sentences = []\n",
    "    if type(paragraph) != str:\n",
    "        print(\"Paragraph must be a string.\")\n",
    "        paragraph = \" \".join(paragraph)\n",
    "    \n",
    "    # Split the string based on . ? and !\n",
    "    punctuation_split = re.split(r\"(\\.|\\?|!)\", paragraph)\n",
    "\n",
    "    # check to make sure that things inside of quotes don't get split based on periods.\n",
    "    \"\"\" for i in range(len(punctuation_split)):\n",
    "        if punctuation_split[i] not in [\".\", \"?\", \"!\"]:\n",
    "            continue\n",
    "        if i < len(punctuation_split) - 1:\n",
    "            if re.search(r\"[A-Za-z0-9]\\s+\\\"\", punctuation_split[i]):\n",
    "                continue\n",
    "        if i > 0:\n",
    "            if re.search(r\"\\\"\\s+[A-Za-z0-9]\", punctuation_split[i-1]):\n",
    "                continue\n",
    "        sentences.append(punctuation_split[i]) \"\"\"\n",
    "\n",
    "    punctuation_marks = [thing for thing in punctuation_split if thing in [\".\", \"?\", \"!\"]]\n",
    "    everything_else = [thing for thing in punctuation_split if thing not in [\".\", \"?\", \"!\"] and len(thing.strip()) > 0]\n",
    "    \n",
    "    if len(punctuation_marks) != len(everything_else):\n",
    "        # add extra periods to counteract the split\n",
    "        if len(punctuation_marks) > len(everything_else):\n",
    "            for i in range(len(punctuation_marks) - len(everything_else)):\n",
    "                everything_else.append(\"\")\n",
    "        else:\n",
    "            for i in range(len(everything_else) - len(punctuation_marks)):\n",
    "                punctuation_marks.append(\".\")\n",
    "\n",
    "    # Write the code to check if sentences are proper\n",
    "    # check for capitalization and length\n",
    "    # If not, combine the sentences until they are proper\n",
    "    # Make sure exclamation points and questions marks are treated as ends of sentences also.\n",
    "    # You may assume that any given paragraph will be less than 500 characters in length.\n",
    "    # Remove all extra spaces.\n",
    "    for i, sentence in enumerate(everything_else):\n",
    "        if len(sentence) > 1:\n",
    "            if sentence[0] == \" \" and (sentence.strip()[0].isupper() or sentence[1] == '\"'):\n",
    "                sentences.append(sentence + punctuation_marks[i])\n",
    "                continue\n",
    "            if sentence[0].isupper() and len(sentence) > 3:\n",
    "                sentences.append(sentence + punctuation_marks[i])\n",
    "            else:  \n",
    "                sentences[-1] += sentence + punctuation_marks[i]\n",
    "\n",
    "    sentences = [s.strip() for s in sentences]\n",
    "    return sentences\n",
    "\n",
    "split_into_sentences(['It was Friday morning. Mike and Maria were getting ready for the day. Maria did not have school, and Mike got the day off from work. They had wanted to go to the amusement park for a while now and were finally going to go today. While Maria made breakfast, Mike was taking a shower.    Maria made French toast with bacon and strawberries on the side. When Mike finished showering, he got dressed and joined Maria for breakfast. \"This tastes delicious!\" said Mike. \"Thanks!\" Maria replied. Mike knew how expensive things can be at an amusement park. He thought it would be a good idea to make lunch to have while there. Mike loved going to amusement parks and sometimes told Maria about them and his experiences. Maria had never been to an amusement park. From hearing about Mike\\'s stories, Maria was both excited and nervous about all the big rides. They made several sandwiches, a fruit salad, and fruit punch. They also planned to take cookies and extra money in case of any emergencies or expenses. Once they were ready, they headed out the door and drove off towards the amusement park. When arriving, they paid for a parking spot and headed towards the entrance of the amusement park. At the entrance, Mike and Maria paid for their admission tickets, and entered the amusement park.24. Going to the Amusement Park (B) '])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "couple/file-24.txt\n",
      "['It was Friday morning. Mike and Maria were getting ready for the day. Maria did not have school, and Mike got the day off from work. They had wanted to go to the amusement park for a while now and were finally going to go today. While Maria made breakfast, Mike was taking a shower.    Maria made French toast with bacon and strawberries on the side. When Mike finished showering, he got dressed and joined Maria for breakfast. \"This tastes delicious!\" said Mike. \"Thanks!\" Maria replied. Mike knew how expensive things can be at an amusement park. He thought it would be a good idea to make lunch to have while there. Mike loved going to amusement parks and sometimes told Maria about them and his experiences. Maria had never been to an amusement park. From hearing about Mike\\'s stories, Maria was both excited and nervous about all the big rides. They made several sandwiches, a fruit salad, and fruit punch. They also planned to take cookies and extra money in case of any emergencies or expenses. Once they were ready, they headed out the door and drove off towards the amusement park. When arriving, they paid for a parking spot and headed towards the entrance of the amusement park. At the entrance, Mike and Maria paid for their admission tickets, and entered the amusement park.24. Going to the Amusement Park (B) ']\n",
      "Paragraph must be a string.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m s \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mrandom_story()\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(s)\n\u001b[1;32m----> 3\u001b[0m split_into_sentences(s)\n",
      "Cell \u001b[1;32mIn[42], line 35\u001b[0m, in \u001b[0;36msplit_into_sentences\u001b[1;34m(paragraph)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(sentence) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m     34\u001b[0m     \u001b[39mif\u001b[39;00m sentence[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m (sentence\u001b[39m.\u001b[39mstrip()[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39misupper() \u001b[39mor\u001b[39;00m sentence[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m---> 35\u001b[0m         sentences\u001b[39m.\u001b[39mappend(sentence \u001b[39m+\u001b[39m punctuation_marks[i])\n\u001b[0;32m     36\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     \u001b[39mif\u001b[39;00m sentence[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39misupper() \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(sentence) \u001b[39m>\u001b[39m \u001b[39m3\u001b[39m:\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "s = util.random_story()\n",
    "print(s)\n",
    "split_into_sentences(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
