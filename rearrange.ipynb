{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import choice\n",
    "\n",
    "# load random story\n",
    "def random_story(folder=None):\n",
    "    if folder is None:\n",
    "        folder = choice(os.listdir('ESL-stuff'))\n",
    "        \n",
    "    story = choice(os.listdir('ESL-stuff/' + folder))\n",
    "    print(folder + '/' + story)\n",
    "    with open('ESL-stuff/' + folder + '/' + story, 'r') as f:\n",
    "        story = f.readlines()\n",
    "        # get rid of empty lines\n",
    "        story = [line for line in story if line != '\\n']\n",
    "    return story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_sentence(story):\n",
    "    \"\"\"Get a random sentence from a story.\"\"\"\n",
    "    paragraph = choice(story).split('. ')\n",
    "    sentence = choice(paragraph)\n",
    "    if len(sentence) < 4: return get_random_sentence(story)\n",
    "\n",
    "    if sentence[0].islower(): return get_random_sentence(story)\n",
    "    \n",
    "    return sentence + \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level/file-4-54.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Sarah was very excited today. It was the first time she was going to ride a horse. Her uncle took her to the stables where the horses were. Horses have always been her favorite animal. When she saw the horses, her heart was filled with excitement. She picked one of the horses to ride. She got her equipment. All laced up and ready to go, she got on the horse. At first the ride was bumpy. Soon enough, she got the hang of it. She felt like she was flying. When it was time to leave, all she could think was when the next time was going to be. ']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story = random_story(\"level\")\n",
    "story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Horses have always been her favorite animal.'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_random_sentence(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find verb in sentence\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "def find_verb(sentence):\n",
    "    verbs = []\n",
    "    pos_tags = pos_tag(word_tokenize(sentence))\n",
    "    print(pos_tags)\n",
    "    for word, tag in pos_tags:\n",
    "        if tag.startswith('VBD') or tag.startswith('VBP'):\n",
    "            verbs.append(word)\n",
    "\n",
    "    if len(verbs) == 0:\n",
    "        for word, tag in pos_tags:\n",
    "            if tag.startswith('VBZ') or tag.startswith('VB'):\n",
    "                verbs.append(word)\n",
    "    return verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('brown')\n",
    "text = nltk.Text(word.lower() for word in nltk.corpus.brown.words())\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def create_similar_word_bank(words, num=4):\n",
    "    bank = set()\n",
    "\n",
    "    for word in words:\n",
    "        # similar_words = wordnet.similar_tos('dog')\n",
    "        for syn in wordnet.synsets(word):\n",
    "            bank.add(syn.lemmas()[0].name())\n",
    "\n",
    "        \"\"\" for word in similar_words:\n",
    "            bank.append(word) \"\"\"\n",
    "        # bank.append(text.similar(word, num=num))\n",
    "\n",
    "    return bank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "couple/file-38.txt\n",
      "[('Mike', 'NNP'), ('and', 'CC'), ('Maria', 'NNP'), ('were', 'VBD'), ('excited', 'VBN'), ('to', 'TO'), ('be', 'VB'), ('celebrating', 'VBG'), ('Halloween', 'NNP'), ('.', '.')]\n",
      "Similar Verbs {'cost', 'be', 'embody', 'constitute', 'exist', 'equal'}\n",
      "['Mike and Maria ____ excited to be celebrating Halloween.']\n"
     ]
    }
   ],
   "source": [
    "sentence = get_random_sentence(random_story())\n",
    "verbs = find_verb(sentence)\n",
    "print(\"Similar Verbs\", create_similar_word_bank(verbs))\n",
    "new_sentence = [sentence.replace(verb, \"_\"*len(verb), 1) for verb in verbs]\n",
    "print(new_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CC - coordinating conjunction\n",
    "\n",
    "CD - cardinal number\n",
    "\n",
    "DT - determiner\n",
    "\n",
    "E - existential there (e.g., \"there is\")\n",
    "\n",
    "FW - foreign word\n",
    "\n",
    "IN - preposition or subordinating conjunction\n",
    "\n",
    "JJ - adjective\n",
    "\n",
    "JJR - comparative adjective\n",
    "\n",
    "JJS - superlative adjective\n",
    "\n",
    "LS - list item marker\n",
    "\n",
    "MD - modal verb\n",
    "\n",
    "NN - noun, singular or mass\n",
    "\n",
    "NNS - noun, plural\n",
    "\n",
    "NNP - proper noun, singular\n",
    "\n",
    "NNPS - proper noun, plural\n",
    "\n",
    "PDT - predeterminer\n",
    "\n",
    "POS - possessive pronoun\n",
    "\n",
    "PRP - personal pronoun\n",
    "\n",
    "PRP$ - possessive pronoun\n",
    "\n",
    "RB - adverb\n",
    "\n",
    "RBR - comparative adverb\n",
    "\n",
    "RBS - superlative adverb\n",
    "\n",
    "詞 - Japanese particle\n",
    "\n",
    "SYM - Chinese character\n",
    "\n",
    "TO - infinitive marker\n",
    "\n",
    "UH - interjection\n",
    "\n",
    "VB - infinitive marker\n",
    "\n",
    "VBD - past tense verb\n",
    "\n",
    "VBG - past participle verb\n",
    "\n",
    "VBN - past participle verb\n",
    "\n",
    "VBP - present tense, perfect, and past participle verb\n",
    "\n",
    "VBZ - present tense, present participle verb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Initialize the WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def get_infinitive_form(word):\n",
    "    return \"to \" + lemmatizer.lemmatize(word, pos='v')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customs/file-75.txt\n",
      "[('The', 'DT'), ('VA', 'NNP'), ('Health', 'NNP'), ('Administration', 'NNP'), ('is', 'VBZ'), ('responsible', 'JJ'), ('for', 'IN'), ('providing', 'VBG'), ('veterans', 'NNS'), ('with', 'IN'), ('all', 'DT'), ('health', 'NN'), ('care', 'NN'), ('issues', 'NNS'), (',', ','), ('while', 'IN'), ('the', 'DT'), ('Benefits', 'NNP'), ('Administration', 'NNP'), ('is', 'VBZ'), ('designed', 'VBN'), ('to', 'TO'), ('help', 'VB'), ('veterans', 'NNS'), ('in', 'IN'), ('areas', 'NNS'), ('such', 'JJ'), ('as', 'IN'), ('guaranteed', 'JJ'), ('home', 'NN'), ('loans', 'NNS'), (',', ','), ('insurance', 'NN'), ('vocational', 'JJ'), ('rehabilitation', 'NN'), ('and', 'CC'), ('educational', 'JJ'), ('benefits', 'NNS'), ('.', '.')]\n",
      "level/file-2-44.txt\n",
      "[('John', 'NNP'), ('sat', 'VBD'), ('on', 'IN'), ('the', 'DT'), ('porch', 'NN'), ('playing', 'VBG'), ('his', 'PRP$'), ('electric', 'JJ'), ('bass', 'NN'), ('.', '.')]\n",
      "sat\n",
      "level/file-1-56.txt\n",
      "[('She', 'PRP'), ('checks', 'VBZ'), ('her', 'PRP'), ('email', 'NN'), ('on', 'IN'), ('it', 'PRP'), ('.', '.')]\n",
      "checks\n",
      "essays/file-46.txt\n",
      "[('They', 'PRP'), ('even', 'RB'), ('sell', 'VBP'), ('beach', 'NN'), ('towels', 'NNS'), ('with', 'IN'), ('body', 'NN'), ('outlines', 'NNS'), ('.', '.')]\n",
      "sell\n",
      "essays/file-9.txt\n",
      "[('The', 'DT'), ('second', 'JJ'), ('part', 'NN'), ('of', 'IN'), ('the', 'DT'), ('meal', 'NN'), ('is', 'VBZ'), ('the', 'DT'), ('washing', 'NN'), ('of', 'IN'), ('hands', 'NNS'), ('.', '.')]\n",
      "is\n",
      "people/file-69.txt\n",
      "[('He', 'PRP'), ('credited', 'VBD'), ('the', 'DT'), ('legendary', 'JJ'), ('comedian', 'NN'), ('Jonathan', 'NNP'), ('Winters', 'NNP'), ('for', 'IN'), ('being', 'VBG'), ('a', 'DT'), ('big', 'JJ'), ('influence', 'NN'), ('on', 'IN'), ('his', 'PRP$'), ('life', 'NN'), ('.', '.')]\n",
      "credited\n",
      "people/file-86.txt\n",
      "[('This', 'DT'), ('project', 'NN'), ('was', 'VBD'), ('designed', 'VBN'), ('to', 'TO'), ('develop', 'VB'), ('a', 'DT'), ('nuclear', 'JJ'), ('weapon', 'NN'), ('in', 'IN'), ('the', 'DT'), ('United', 'NNP'), ('States', 'NNPS'), ('in', 'IN'), ('case', 'NN'), ('Hitler', 'NNP'), ('unleashed', 'VBD'), ('his', 'PRP$'), ('own', 'JJ'), ('weapon', 'NN'), ('.', '.')]\n",
      "level/file-1-17.txt\n",
      "[('Kids', 'NNS'), ('sit', 'VBD'), ('next', 'JJ'), ('to', 'TO'), ('it', 'PRP'), ('.', '.')]\n",
      "sit\n",
      "essays/file-75.txt\n",
      "[('The', 'DT'), ('United', 'NNP'), ('States', 'NNPS'), ('Department', 'NNP'), ('of', 'IN'), ('Veterans', 'NNP'), ('Affairs', 'NNPS'), (',', ','), ('more', 'JJR'), ('commonly', 'RB'), ('known', 'VBN'), ('as', 'IN'), ('the', 'DT'), ('Veterans', 'NNPS'), ('Administration', 'NNP'), (',', ','), ('is', 'VBZ'), ('an', 'DT'), ('organization', 'NN'), ('dedicated', 'VBN'), ('to', 'TO'), ('provide', 'VB'), ('services', 'NNS'), ('for', 'IN'), ('all', 'DT'), ('veterans', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('U.S', 'NNP'), ('.', '.')]\n",
      "couple/file-16.txt\n",
      "[('The', 'DT'), ('night', 'NN'), ('ended', 'VBN'), ('pleasantly', 'RB'), ('.', '.')]\n",
      "ended\n",
      "essays/file-10.txt\n",
      "[('According', 'VBG'), ('to', 'TO'), ('the', 'DT'), ('myth', 'NN'), ('the', 'DT'), ('Easter', 'NNP'), ('Bunny', 'NNP'), ('leaves', 'VBZ'), ('baskets', 'NNS'), ('full', 'JJ'), ('of', 'IN'), ('candy', 'NN'), ('for', 'IN'), ('children', 'NNS'), ('.', '.')]\n",
      "essays/file-10.txt\n",
      "[('It', 'PRP'), ('is', 'VBZ'), ('associated', 'VBN'), ('with', 'IN'), ('the', 'DT'), ('beginning', 'NN'), ('of', 'IN'), ('spring', 'NN'), ('and', 'CC'), ('symbolized', 'VBN'), ('by', 'IN'), ('bunnies', 'NNS'), (',', ','), ('flowers', 'NNS'), (',', ','), ('and', 'CC'), ('dyed', 'VBD'), ('eggs', 'NNS'), ('.', '.')]\n",
      "dyed\n",
      "level/file-1-19.txt\n",
      "[('All', 'PDT'), ('the', 'DT'), ('team', 'NN'), ('members', 'NNS'), ('meet', 'VBP'), ('at', 'IN'), ('Mary', 'NNP'), (\"'s\", 'POS'), ('house', 'NN'), ('.', '.')]\n",
      "meet\n",
      "couple/file-47.txt\n",
      "[('``', '``'), ('Why', 'WRB'), ('do', 'VBP'), ('you', 'PRP'), ('have', 'VB'), ('your', 'PRP$'), ('hand', 'NN'), ('behind', 'IN'), ('your', 'PRP$'), ('back', 'NN'), ('?', '.'), (\"''\", \"''\"), ('she', 'PRP'), ('asked', 'VBD'), ('when', 'WRB'), ('she', 'PRP'), ('noticed', 'VBD'), ('Mike', 'NNP'), (\"'s\", 'POS'), ('awkward', 'JJ'), ('stance', 'NN'), ('.', '.')]\n",
      "level/file-3-58.txt\n",
      "[('He', 'PRP'), ('thought', 'VBD'), ('Karen', 'NNP'), ('was', 'VBD'), ('very', 'RB'), ('nice', 'JJ'), ('and', 'CC'), ('funny', 'JJ'), ('.', '.')]\n",
      "essays/file-44.txt\n",
      "[('The', 'DT'), ('double-ended', 'JJ'), ('cars', 'NNS'), ('are', 'VBP'), ('a', 'DT'), ('bit', 'NN'), ('larger', 'JJR'), (',', ','), ('and', 'CC'), ('can', 'MD'), ('hold', 'VB'), ('up', 'RP'), ('to', 'TO'), ('68', 'CD'), ('passengers', 'NNS'), ('.', '.')]\n",
      "are\n",
      "couple/file-18.txt\n",
      "[('It', 'PRP'), ('was', 'VBD'), ('going', 'VBG'), ('to', 'TO'), ('be', 'VB'), ('dark', 'JJ'), ('soon.18', 'NN'), ('.', '.')]\n",
      "was\n",
      "level/file-4-52.txt\n",
      "[('``', '``'), ('Are', 'VBP'), ('you', 'PRP'), ('sure', 'JJ'), ('?', '.'), (\"''\", \"''\"), ('her', 'PRP$'), ('mom', 'NN'), ('asked', 'VBD'), ('.', '.')]\n",
      "level/file-4-92.txt\n",
      "[('It', 'PRP'), ('was', 'VBD'), ('a', 'DT'), ('wallet', 'NN'), ('.', '.')]\n",
      "was\n",
      "customs/file-21.txt\n",
      "[('There', 'EX'), ('are', 'VBP'), ('tax', 'NN'), ('credits', 'NNS'), ('that', 'WDT'), ('people', 'NNS'), ('with', 'IN'), ('low', 'JJ'), ('income', 'NN'), (',', ','), ('college', 'NN'), ('students', 'NNS'), (',', ','), ('and', 'CC'), ('parents', 'NNS'), ('can', 'MD'), ('get', 'VB'), ('.', '.')]\n",
      "are\n",
      "level/file-6-23.txt\n",
      "[('She', 'PRP'), ('started', 'VBD'), ('to', 'TO'), ('form', 'VB'), ('a', 'DT'), ('connection', 'NN'), ('with', 'IN'), ('the', 'DT'), ('dog', 'NN'), (',', ','), ('but', 'CC'), ('she', 'PRP'), ('knew', 'VBD'), ('she', 'PRP'), ('could', 'MD'), ('not', 'RB'), ('keep', 'VB'), ('him', 'PRP'), ('.', '.')]\n",
      "level/file-4-84.txt\n",
      "[('He', 'PRP'), ('was', 'VBD'), ('also', 'RB'), ('tired', 'VBN'), ('of', 'IN'), ('staying', 'VBG'), ('at', 'IN'), ('home', 'NN'), (',', ','), ('so', 'IN'), ('he', 'PRP'), ('decided', 'VBD'), ('to', 'TO'), ('volunteer', 'VB'), ('.', '.')]\n",
      "people/file-32.txt\n",
      "[('The', 'DT'), ('English', 'NNP'), ('Parliament', 'NNP'), ('had', 'VBD'), ('issued', 'VBN'), ('two', 'CD'), ('unpopular', 'JJ'), ('taxes', 'NNS'), (',', ','), ('which', 'WDT'), ('were', 'VBD'), ('imposed', 'VBN'), ('to', 'TO'), ('help', 'VB'), ('support', 'VB'), ('the', 'DT'), ('British', 'JJ'), ('after', 'IN'), ('the', 'DT'), ('end', 'NN'), ('of', 'IN'), ('the', 'DT'), ('Seven', 'NNP'), ('Years', 'NNP'), ('War', 'NNP'), ('.', '.')]\n",
      "customs/file-41.txt\n",
      "[('It', 'PRP'), ('is', 'VBZ'), ('a', 'DT'), ('great', 'JJ'), ('place', 'NN'), ('for', 'IN'), ('a', 'DT'), ('family', 'NN'), ('vacation', 'NN'), ('with', 'IN'), ('many', 'JJ'), ('of', 'IN'), ('its', 'PRP$'), ('campsites', 'NNS'), ('open', 'JJ'), ('year', 'NN'), ('round', 'NN'), ('.', '.')]\n",
      "is\n",
      "couple/file-10.txt\n",
      "[('The', 'DT'), ('day', 'NN'), ('of', 'IN'), ('the', 'DT'), ('steakhouse', 'NN'), ('dinner', 'NN'), ('arrived', 'VBD'), ('.', '.')]\n",
      "arrived\n",
      "customs/file-47.txt\n",
      "[('A', 'DT'), ('visitor', 'NN'), ('can', 'MD'), ('visit', 'VB'), ('an', 'DT'), ('entire', 'JJ'), ('Egyptian', 'JJ'), ('tomb', 'NN'), (',', ','), ('sit', 'NN'), ('in', 'IN'), ('a', 'DT'), ('Japanese', 'JJ'), ('style', 'NN'), ('garden', 'NN'), (',', ','), ('view', 'NN'), ('Renaissance', 'NNP'), ('paintings', 'NNS'), (',', ','), ('and', 'CC'), ('ancient', 'JJ'), ('Greek', 'NNP'), ('and', 'CC'), ('Roman', 'NNP'), ('sculptures', 'NNS'), ('.', '.')]\n",
      "visit\n",
      "essays/file-50.txt\n",
      "[('Radio', 'NNP'), ('City', 'NNP'), ('Music', 'NNP'), ('Hall', 'NNP'), ('is', 'VBZ'), ('another', 'DT'), ('famous', 'JJ'), ('building', 'NN'), ('in', 'IN'), ('Rockefeller', 'NNP'), ('Center', 'NNP'), ('.', '.')]\n",
      "is\n",
      "customs/file-11.txt\n",
      "[('Mother', 'NNP'), (\"'s\", 'POS'), ('Day', 'NNP'), ('is', 'VBZ'), ('also', 'RB'), ('the', 'DT'), ('most', 'RBS'), ('popular', 'JJ'), ('day', 'NN'), ('to', 'TO'), ('make', 'VB'), ('long', 'JJ'), ('distance', 'NN'), ('calls', 'VBZ'), ('in', 'IN'), ('the', 'DT'), ('U.S', 'NNP'), ('.', '.')]\n",
      "customs/file-16.txt\n",
      "[('In', 'IN'), ('the', 'DT'), ('U.S', 'NNP'), ('.', '.')]\n",
      "people/file-90.txt\n",
      "[('Her', 'PRP$'), ('first', 'JJ'), ('autobiography', 'NN'), ('I', 'PRP'), ('Know', 'VBP'), ('Why', 'WRB'), ('the', 'DT'), ('Caged', 'NNP'), ('Bird', 'NNP'), ('Sings', 'NNP'), ('received', 'VBD'), ('critical', 'JJ'), ('acclaim', 'NN'), ('.', '.')]\n",
      "people/file-82.txt\n",
      "[('His', 'PRP$'), ('defining', 'VBG'), ('moment', 'NN'), ('may', 'MD'), ('have', 'VB'), ('been', 'VBN'), ('his', 'PRP$'), ('command', 'NN'), ('of', 'IN'), ('American', 'JJ'), ('forces', 'NNS'), ('during', 'IN'), ('the', 'DT'), ('infamous', 'JJ'), ('Battle', 'NNP'), ('of', 'IN'), ('the', 'DT'), ('Bulge', 'NNP'), ('.', '.')]\n",
      "customs/file-92.txt\n",
      "[('Some', 'DT'), ('also', 'RB'), ('organize', 'JJ'), ('activities', 'NNS'), ('for', 'IN'), ('people', 'NNS'), ('who', 'WP'), ('like', 'IN'), ('sing-alongs', 'NNS'), (',', ','), ('where', 'WRB'), ('people', 'NNS'), ('will', 'MD'), ('gather', 'VB'), ('together', 'RB'), ('and', 'CC'), ('sing', 'JJ'), ('songs', 'NNS'), ('.', '.')]\n",
      "gather\n",
      "customs/file-13.txt\n",
      "[('Arlington', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('military', 'JJ'), ('cemetery', 'NN'), (',', ','), ('meaning', 'VBG'), ('only', 'RB'), ('military', 'JJ'), ('personnel', 'NNS'), ('are', 'VBP'), ('buried', 'VBN'), ('there', 'RB'), ('.', '.')]\n",
      "are\n",
      "essays/file-65.txt\n",
      "[('The', 'DT'), ('New', 'NNP'), ('England', 'NNP'), ('city', 'NN'), ('is', 'VBZ'), ('called', 'VBN'), ('the', 'DT'), ('Witch', 'NNP'), ('City', 'NNP'), ('because', 'IN'), ('of', 'IN'), ('an', 'DT'), ('infamous', 'JJ'), ('set', 'NN'), ('of', 'IN'), ('trials', 'NNS'), ('that', 'WDT'), ('happened', 'VBD'), ('there', 'RB'), ('in', 'IN'), ('1692', 'CD'), ('to', 'TO'), ('1693', 'CD'), ('.', '.')]\n",
      "happened\n",
      "customs/file-9.txt\n",
      "[('The', 'DT'), ('matzo', 'NN'), ('and', 'CC'), ('other', 'JJ'), ('foods', 'NNS'), ('are', 'VBP'), ('eaten', 'VBN'), ('at', 'IN'), ('a', 'DT'), ('special', 'JJ'), ('meal', 'NN'), ('called', 'VBD'), ('a', 'DT'), ('seder', 'NN'), ('.', '.')]\n",
      "level/file-5-60.txt\n",
      "[('He', 'PRP'), ('talks', 'VBZ'), ('to', 'TO'), ('people', 'NNS'), ('at', 'IN'), ('the', 'DT'), ('park', 'NN'), ('and', 'CC'), ('has', 'VBZ'), ('good', 'JJ'), ('conversations', 'NNS'), ('.', '.')]\n",
      "couple/file-22.txt\n",
      "[('She', 'PRP'), ('had', 'VBD'), ('an', 'DT'), ('essay', 'NN'), ('to', 'TO'), ('complete', 'VB'), ('and', 'CC'), ('a', 'DT'), ('math', 'NN'), ('assignment', 'NN'), ('as', 'RB'), ('well', 'RB'), ('.', '.')]\n",
      "had\n",
      "level/file-3-4.txt\n",
      "[('Lisa', 'NNP'), ('had', 'VBD'), ('even', 'RB'), ('heard', 'JJ'), ('people', 'NNS'), ('say', 'VBP'), ('she', 'PRP'), ('was', 'VBD'), ('the', 'DT'), ('ugly', 'RB'), ('sister', 'NN'), ('.', '.')]\n",
      "level/file-4-24.txt\n",
      "[('They', 'PRP'), ('were', 'VBD'), ('upset', 'VBN'), ('.', '.')]\n",
      "were\n",
      "customs/file-82.txt\n",
      "[('Usually', 'RB'), ('there', 'EX'), ('is', 'VBZ'), ('a', 'DT'), ('little', 'JJ'), ('bit', 'NN'), ('of', 'IN'), ('time', 'NN'), (',', ','), ('about', 'IN'), ('an', 'DT'), ('hour', 'NN'), (',', ','), ('between', 'IN'), ('the', 'DT'), ('ceremony', 'NN'), ('and', 'CC'), ('the', 'DT'), ('reception', 'NN'), ('to', 'TO'), ('give', 'VB'), ('people', 'NNS'), ('enough', 'JJ'), ('time', 'NN'), ('to', 'TO'), ('travel', 'VB'), ('from', 'IN'), ('the', 'DT'), ('ceremony', 'NN'), ('location', 'NN'), ('to', 'TO'), ('the', 'DT'), ('reception', 'NN'), ('location', 'NN'), ('.', '.')]\n",
      "essays/file-33.txt\n",
      "[('Once', 'RB'), ('you', 'PRP'), ('get', 'VBP'), ('your', 'PRP$'), ('driver', 'NN'), (\"'s\", 'POS'), ('license', 'NN'), ('in', 'IN'), ('one', 'CD'), ('state', 'NN'), (',', ','), ('you', 'PRP'), ('can', 'MD'), ('use', 'VB'), ('it', 'PRP'), ('to', 'TO'), ('drive', 'VB'), ('in', 'IN'), ('all', 'DT'), ('of', 'IN'), ('the', 'DT'), ('United', 'NNP'), ('States', 'NNPS'), ('.', '.')]\n",
      "get\n",
      "level/file-6-18.txt\n",
      "[('They', 'PRP'), ('could', 'MD'), ('help', 'VB'), ('her', 'PRP$'), ('move', 'NN'), ('into', 'IN'), ('her', 'PRP$'), ('new', 'JJ'), ('apartment', 'NN'), ('.', '.')]\n",
      "help\n",
      "people/file-65.txt\n",
      "[('The', 'DT'), ('case', 'NN'), ('was', 'VBD'), ('settled', 'VBN'), (',', ','), ('but', 'CC'), ('it', 'PRP'), ('continues', 'VBZ'), ('to', 'TO'), ('be', 'VB'), ('an', 'DT'), ('issue', 'NN'), ('.', '.')]\n",
      "was\n",
      "customs/file-74.txt\n",
      "[('The', 'DT'), ('1960s', 'CD'), ('was', 'VBD'), ('an', 'DT'), ('impactful', 'JJ'), ('era', 'NN'), ('in', 'IN'), ('American', 'JJ'), ('history', 'NN'), ('.', '.')]\n",
      "was\n",
      "level/file-1-72.txt\n",
      "[('Sometimes', 'RB'), ('it', 'PRP'), ('is', 'VBZ'), ('an', 'DT'), ('actress', 'NN'), ('.', '.')]\n",
      "is\n",
      "customs/file-37.txt\n",
      "[('They', 'PRP'), ('think', 'VBP'), ('of', 'IN'), ('death', 'NN'), ('as', 'IN'), ('a', 'DT'), ('solemn', 'NN'), ('and', 'CC'), ('sad', 'JJ'), ('occasion', 'NN'), (',', ','), ('not', 'RB'), ('a', 'DT'), ('time', 'NN'), ('to', 'TO'), ('pose', 'VB'), ('the', 'DT'), ('dead', 'JJ'), ('as', 'IN'), ('if', 'IN'), ('they', 'PRP'), ('were', 'VBD'), ('toys', 'NNS'), ('.', '.')]\n",
      "people/file-63.txt\n",
      "[('This', 'DT'), ('is', 'VBZ'), ('when', 'WRB'), ('and', 'CC'), ('where', 'WRB'), ('Jobs', 'NNP'), ('developed', 'VBD'), ('his', 'PRP$'), ('interest', 'NN'), ('in', 'IN'), ('mechanical', 'JJ'), ('reconstruction', 'NN'), ('.', '.')]\n",
      "developed\n",
      "couple/file-8.txt\n",
      "[('History', 'NN'), ('was', 'VBD'), ('the', 'DT'), ('subject', 'NN'), ('she', 'PRP'), ('was', 'VBD'), ('majoring', 'VBG'), ('in', 'IN'), ('at', 'IN'), ('the', 'DT'), ('university', 'NN'), ('.', '.')]\n",
      "people/file-37.txt\n",
      "[('His', 'PRP$'), ('style', 'NN'), ('developed', 'VBD'), ('at', 'IN'), ('an', 'DT'), ('early', 'JJ'), ('age', 'NN'), ('when', 'WRB'), ('he', 'PRP'), ('was', 'VBD'), ('playing', 'VBG'), ('basketball', 'NN'), ('in', 'IN'), ('his', 'PRP$'), ('home', 'NN'), ('state', 'NN'), ('of', 'IN'), ('Michigan', 'NNP'), ('.', '.')]\n",
      "couple/file-5.txt\n",
      "[('Finding', 'VBG'), ('an', 'DT'), ('Apartment', 'NN'), ('(', '('), ('B', 'NNP'), (')', ')'), ('.', '.')]\n",
      "Finding\n",
      "level/file-3-40.txt\n",
      "[('His', 'PRP$'), ('friends', 'NNS'), ('were', 'VBD'), ('going', 'VBG'), ('to', 'TO'), ('show', 'VB'), ('him', 'PRP'), ('around', 'RB'), ('.', '.')]\n",
      "were\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "problems = int(input(\"Enter the number of questions\"))\n",
    "while len(sentences) < problems:\n",
    "    random_sentence = get_random_sentence(random_story())\n",
    "    verbs = find_verb(random_sentence)\n",
    "\n",
    "    if len(verbs) > 1 or len(verbs) == 0: continue\n",
    "\n",
    "    new = random_sentence.replace(verbs[0], \"_\"*len(verbs[0]), 1)\n",
    "    print(verbs[0])\n",
    "\n",
    "    if new not in sentences:\n",
    "        sentences.append([new + f\" ({get_infinitive_form(verbs[0])})\", verbs[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFill in the Verb\n",
      "\n",
      "1. John ___ on the porch playing his electric bass. (to sit)\n",
      "2. She ______ her email on it. (to check)\n",
      "3. They even ____ beach towels with body outlines. (to sell)\n",
      "4. The second part of the meal __ the washing of hands. (to be)\n",
      "5. He ________ the legendary comedian Jonathan Winters for being a big influence on his life. (to credit)\n",
      "6. Kids ___ next to it. (to sit)\n",
      "7. The night _____ pleasantly. (to end)\n",
      "8. It is associated with the beginning of spring and symbolized by bunnies, flowers, and ____ eggs. (to dye)\n",
      "9. All the team members ____ at Mary's house. (to meet)\n",
      "10. The double-ended cars ___ a bit larger, and can hold up to 68 passengers. (to be)\n",
      "11. It ___ going to be dark soon.18. (to be)\n",
      "12. It ___ a wallet. (to be)\n",
      "13. There ___ tax credits that people with low income, college students, and parents can get. (to be)\n",
      "14. It __ a great place for a family vacation with many of its campsites open year round. (to be)\n",
      "15. The day of the steakhouse dinner _______. (to arrive)\n",
      "16. A _____or can visit an entire Egyptian tomb, sit in a Japanese style garden, view Renaissance paintings, and ancient Greek and Roman sculptures. (to visit)\n",
      "17. Radio City Music Hall __ another famous building in Rockefeller Center. (to be)\n",
      "18. Some also organize activities for people who like sing-alongs, where people will ______ together and sing songs. (to gather)\n",
      "19. Arlington is a military cemetery, meaning only military personnel ___ buried there. (to be)\n",
      "20. The New England city is called the Witch City because of an infamous set of trials that ________ there in 1692 to 1693. (to happen)\n",
      "21. She ___ an essay to complete and a math assignment as well. (to have)\n",
      "22. They ____ upset. (to be)\n",
      "23. Once you ___ your driver's license in one state, you can use it to drive in all of the United States. (to get)\n",
      "24. They could ____ her move into her new apartment. (to help)\n",
      "25. The case ___ settled, but it continues to be an issue. (to be)\n",
      "26. The 1960s ___ an impactful era in American history. (to be)\n",
      "27. Sometimes it __ an actress. (to be)\n",
      "28. This is when and where Jobs _________ his interest in mechanical reconstruction. (to develop)\n",
      "29. _______ an Apartment (B) . (to Finding)\n",
      "30. His friends ____ going to show him around. (to be)\n",
      "\n",
      "\n",
      "1. sat\n",
      "2. checks\n",
      "3. sell\n",
      "4. is\n",
      "5. credited\n",
      "6. sit\n",
      "7. ended\n",
      "8. dyed\n",
      "9. meet\n",
      "10. are\n",
      "11. was\n",
      "12. was\n",
      "13. are\n",
      "14. is\n",
      "15. arrived\n",
      "16. visit\n",
      "17. is\n",
      "18. gather\n",
      "19. are\n",
      "20. happened\n",
      "21. had\n",
      "22. were\n",
      "23. get\n",
      "24. help\n",
      "25. was\n",
      "26. was\n",
      "27. is\n",
      "28. developed\n",
      "29. Finding\n",
      "30. were\n",
      "\n"
     ]
    }
   ],
   "source": [
    "worksheet = \"\\tFill in the Verb\\n\\n\"\n",
    "\n",
    "for index, sentence in enumerate(sentences): \n",
    "    worksheet += f\"{index + 1}. {sentence[0]}\\n\"\n",
    "\n",
    "worksheet += \"\\n\\n\\tAnswer Key\\n\\n\"\n",
    "\n",
    "for index, sentence in enumerate(sentences):\n",
    "    worksheet += f\"{index + 1}. {sentence[1]}\\n\"\n",
    "\n",
    "print(worksheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternate Definitions\n",
      "the event of something burning (often destructive)\n",
      "the act of firing weapons or artillery at an enemy\n",
      "the process of combustion of inflammable materials producing heat and light and (often) smoke\n",
      "a fireplace in which a relatively small fire is burning\n",
      "once thought to be one of four elements composing the universe (Empedocles)\n",
      "feelings of great warmth and intensity\n",
      "fuel that is burning and is used as a means for cooking\n",
      "a severe trial\n",
      "intense adverse criticism\n",
      "start firing a weapon\n",
      "cause to go off\n",
      "bake in a kiln so as to harden\n",
      "terminate the employment of; discharge from an office or position\n",
      "go off or discharge\n",
      "drive out or away by or as if by fire\n",
      "call forth (emotions, feelings, and responses)\n",
      "destroy by fire\n",
      "provide with fuel\n"
     ]
    }
   ],
   "source": [
    "word = \"fires\"\n",
    "\n",
    "print(\"Alternate Definitions\")\n",
    "for syn in wordnet.synsets(word):\n",
    "    print(syn.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all complex nouns in sentence\n",
    "# input: sentence\n",
    "# output: list of complex nouns\n",
    "def get_complex_nouns(sentence):\n",
    "    nouns = []\n",
    "    for chunk in sentence.noun_chunks:\n",
    "        if len(chunk.text.split()) > 1:\n",
    "            nouns.append(chunk.text)\n",
    "    return nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customs/file-44.txt\n",
      "One of the most historic, and significant landmarks in the United States is the San Francisco cable car system. It is the world's only, manually operated cable car system. It is run by the San Francisco Municipal Transportation Agency. The system dates back to 1878, when the California Street line first opened. In all, there are three lines currently operating in the city, and boasts a fleet of 12 cable cars. There used to be 23 lines in use throughout the city connecting the diverse communities that make up San Francisco. The open-air cars are a major tourist attraction, and are still used by San Francisco commuters on a daily basis. The simple reason cable cars were first used in the city was because of its landscape. San Francisco is very hilly, which makes it impossible for municipal buses to scale. The solution for this problem was the cable car. These cars are literally pulled by cable, up and down the steep hills of the city, making it easier for people to get from one end of the city to the other. There are two types of cars in use today. Single-ended cars and double-ended cars. The single-ended cars have open-sided sections with seats that face outward to the street. The rear section of these cars is enclosed with seats facing the interior of the car. These cars seat 29 passengers. They travel in both directions by using a swivel-based turntable that turns the car at the end of the line. The double-ended cars are a bit larger, and can hold up to 68 passengers. It has 34 seats, and grips for an additional 34 standing passengers. The best feature of these cars is the pure fun they are to ride. People who ride the San Francisco cable cars are stepping into part of California's history.  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One: 0.64\n",
      "of: 0.00\n",
      "the: 0.00\n",
      "most: 0.19\n",
      "historic: 6.67\n",
      ",: 0.00\n",
      "and: 0.00\n",
      "significant: 5.18\n",
      "landmarks: 45.00\n",
      "in: 0.01\n",
      "United: 1.03\n",
      "States: 1.48\n",
      "is: 0.03\n",
      "San: 0.00\n",
      "Francisco: 0.00\n",
      "cable: 80.00\n",
      "car: 0.55\n",
      "system: 1.37\n",
      ".: 0.00\n",
      "It: 0.01\n",
      "world: 0.66\n",
      "'s: 0.00\n",
      "only: 0.22\n",
      "manually: 20.00\n",
      "operated: 20.00\n",
      "run: 8.26\n",
      "by: 0.01\n",
      "Municipal: 90.00\n",
      "Transportation: 168.00\n",
      "Agency: 33.33\n",
      "The: 0.00\n",
      "dates: 20.97\n",
      "back: 1.18\n",
      "to: 0.00\n",
      "1878: 0.00\n",
      "when: 0.00\n",
      "California: 1.52\n",
      "Street: 3.03\n",
      "line: 5.09\n",
      "first: 0.64\n",
      "opened: 6.36\n",
      "In: 0.08\n",
      "all: 0.03\n",
      "there: 0.11\n",
      "are: 0.10\n",
      "three: 0.27\n",
      "lines: 9.23\n",
      "currently: 2.73\n",
      "operating: 9.88\n",
      "city: 0.46\n",
      "boasts: 60.00\n",
      "a: 0.00\n",
      "fleet: 26.92\n",
      "12: 0.41\n",
      "cars: 1.82\n",
      "There: 0.23\n",
      "used: 0.59\n",
      "be: 0.04\n",
      "23: 0.83\n",
      "use: 0.69\n",
      "throughout: 1.63\n",
      "connecting: 157.14\n",
      "diverse: 10.00\n",
      "communities: 15.71\n",
      "that: 0.00\n",
      "make: 2.65\n",
      "up: 0.15\n",
      "open-air: 40.00\n",
      "major: 2.85\n",
      "tourist: 4.38\n",
      "attraction: 31.25\n",
      "still: 1.23\n",
      "commuters: 180.00\n",
      "on: 0.02\n",
      "daily: 2.50\n",
      "basis: 0.81\n",
      "simple: 3.46\n",
      "reason: 2.25\n",
      "were: 0.16\n",
      "was: 0.04\n",
      "because: 0.00\n",
      "its: 0.02\n",
      "landscape: 25.71\n",
      "very: 0.21\n",
      "hilly: 50.00\n",
      "which: 0.00\n",
      "makes: 15.18\n",
      "it: 0.00\n",
      "impossible: 4.82\n",
      "for: 0.00\n",
      "municipal: 6.43\n",
      "buses: 43.75\n",
      "scale: 16.07\n",
      "solution: 7.02\n",
      "this: 0.00\n",
      "problem: 0.67\n",
      "These: 0.00\n",
      "literally: 6.67\n",
      "pulled: 13.78\n",
      "down: 1.17\n",
      "steep: 21.43\n",
      "hills: 7.89\n",
      "making: 12.33\n",
      "easier: 14.12\n",
      "people: 0.44\n",
      "get: 1.54\n",
      "from: 0.00\n",
      "one: 0.09\n",
      "end: 1.35\n",
      "other: 0.12\n",
      "two: 0.07\n",
      "types: 3.48\n",
      "today: 0.81\n",
      "Single-ended: 0.00\n",
      "double-ended: 0.00\n",
      "single-ended: 0.00\n",
      "have: 0.21\n",
      "open-sided: 0.00\n",
      "sections: 18.18\n",
      "with: 0.00\n",
      "seats: 56.67\n",
      "face: 2.37\n",
      "outward: 19.09\n",
      "street: 2.04\n",
      "rear: 8.63\n",
      "section: 7.89\n",
      "these: 0.00\n",
      "enclosed: 33.33\n",
      "facing: 24.38\n",
      "interior: 13.62\n",
      "seat: 11.64\n",
      "29: 1.67\n",
      "passengers: 4.55\n",
      "They: 0.00\n",
      "travel: 9.64\n",
      "both: 0.06\n",
      "directions: 34.62\n",
      "using: 2.63\n",
      "swivel-based: 0.00\n",
      "turntable: 135.00\n",
      "turns: 48.72\n",
      "at: 0.01\n",
      "bit: 4.41\n",
      "larger: 3.90\n",
      "can: 0.14\n",
      "hold: 11.04\n",
      "68: 2.86\n",
      "has: 0.25\n",
      "34: 0.91\n",
      "grips: 55.56\n",
      "an: 0.01\n",
      "additional: 0.93\n",
      "standing: 17.32\n",
      "best: 5.03\n",
      "feature: 15.14\n",
      "pure: 5.09\n",
      "fun: 2.73\n",
      "they: 0.00\n",
      "ride: 13.91\n",
      "People: 9.73\n",
      "who: 0.01\n",
      "stepping: 80.00\n",
      "into: 0.00\n",
      "part: 1.55\n",
      "history: 1.30\n",
      "\n",
      "Top 5 words with highest lexical scores:\n",
      "commuters: 180.00\n",
      "Transportation: 168.00\n",
      "connecting: 157.14\n",
      "turntable: 135.00\n",
      "Municipal: 90.00\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK resources (if not already downloaded)\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('words')\n",
    "\n",
    "# Sample sentence\n",
    "# sentence = \"This is a complicated sentence with various intricate words and powerful emotions.\"\n",
    "story = random_story()\n",
    "sentence = \"\"\n",
    "\n",
    "for sent in story:\n",
    "    sentence += sent + \" \"\n",
    "\n",
    "print(sentence)\n",
    "\n",
    "# Tokenize the sentence\n",
    "words = word_tokenize(sentence)\n",
    "\n",
    "# Calculate word frequency using NLTK's FreqDist\n",
    "word_freq = FreqDist(words)\n",
    "\n",
    "corpus = nltk.corpus.brown.words()  # Replace with your own corpus if available\n",
    "corpus_freq = FreqDist(corpus)\n",
    "\n",
    "# Function to calculate lexical score based on word frequency\n",
    "def calculate_lexical_score(word):\n",
    "    synsets = wordnet.synsets(word)\n",
    "    if synsets:\n",
    "        # Consider the number of synsets (senses) for the word\n",
    "        return len(synsets) * 10 * len(word) / (corpus_freq[word] + 1)\n",
    "    else:\n",
    "        # Assign a low score to words not found in WordNet\n",
    "        return 0  # You can adjust this as needed\n",
    "\n",
    "# Calculate lexical scores for each word in the sentence\n",
    "lexical_scores = {word: calculate_lexical_score(word) for word in words}\n",
    "\n",
    "# Print the lexical scores\n",
    "for word, score in lexical_scores.items():\n",
    "    print(f\"{word}: {score:.2f}\")\n",
    "\n",
    "# Print top 5 words with highest lexical scores\n",
    "print(\"\\nTop 5 words with highest lexical scores:\")\n",
    "for word, score in sorted(lexical_scores.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "    print(f\"{word}: {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import SyllableTokenizer\n",
    "\n",
    "# Initialize the SyllableTokenizer\n",
    "tokenizer = SyllableTokenizer()\n",
    "\n",
    "def get_syllables(word):\n",
    "    # Use the SyllableTokenizer to break the word into syllables\n",
    "    syllables = tokenizer.tokenize(word)\n",
    "\n",
    "    # Join the syllables with a dot (·)\n",
    "    syllables_with_dots = ' · '.join(syllables)\n",
    "\n",
    "    # Print the word with syllables separated by dots\n",
    "    return syllables_with_dots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import cmudict\n",
    "nltk.download('cmudict')\n",
    "\n",
    "def get_sounds(text):\n",
    "    d = cmudict.dict()\n",
    "\n",
    "    phonetics = d[text.lower()]\n",
    "\n",
    "    sounds = [sound[:-1] if sound[-1] in \"0123\" else sound for sound in phonetics[0]]\n",
    "    line = \" \".join(sounds)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "essays/file-85.txt\n",
      "Who says adult parties have to be boring. More and more adults are reliving their childhoods or creating memories they didn't have as children by having theme parties for their birthday or other occasions. Theme parties are based on an idea, a television show, a fictional character, or really anything. Sometimes guests are expected to dress according to the theme as well. For example, the Toga party is a type of theme party where guests are expected to dress in togas, really just white sheets. Toga parties used to be especially popular among college students. In a masquerade party, everyone wears a mask and has to guess who is behind it. The mystery is part of the fun. Speaking of mystery, there are murder mystery parties, where the guests have to solve a fake murder. Some adults throw parties based on seasons. A summer beach party, for example, might feature guests wearing their swimsuits. Another popular type of theme party is the game night party. In this type of party, people get together to play  various board games. A variation of the game night party is the casino party, where adults play games typically found in a casino-like blackjack or poker. Another theme party could focus on a specific region or country. For example, a Mexican theme party might feature tacos, the colors of the Mexican flag and Mexican music. Guests should be careful when dressing up for these types of theme parties though. Dressing up like a certain ethnic or racial group is usually considered offensive. It's better to just enjoy the food, and not portray a stereotype. \n",
      "Infinitive Verbs: ['be', 'have', 'dress', 'dress', 'be', 'guess', 'solve', 'feature', 'play', 'focus', 'feature', 'be', 'enjoy', 'portray']\n",
      "Past Tense Verbs: ['did', 'used']\n",
      "Present Participle Verbs (Gerunds): ['boring', 'reliving', 'creating', 'having', 'according', 'wearing', 'dressing', 'Dressing']\n",
      "Past Participle Verbs: ['based', 'expected', 'expected', 'based', 'found', 'considered']\n",
      "Present Simple Verbs (3rd person singular and present participle): ['says', 'have', 'are', 'are', 'are', 'is', 'are', 'wears', 'has', 'is', 'is', 'are', 'have', 'throw', 'is', 'get', 'is', 'play', 'is', \"'s\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "# Download NLTK resources (if not already downloaded)\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Sentence containing verbs with different tenses\n",
    "story = random_story()\n",
    "sentence = \" \".join(story)\n",
    "print(sentence)\n",
    "\n",
    "# Tokenize the sentence\n",
    "words = word_tokenize(sentence)\n",
    "\n",
    "# Perform part-of-speech tagging\n",
    "pos_tags = pos_tag(words)\n",
    "\n",
    "# Initialize lists to categorize verbs by tense\n",
    "infinitive_verbs = []\n",
    "past_tense_verbs = []\n",
    "present_participle_verbs = []\n",
    "past_participle_verbs = []\n",
    "present_simple_verbs = []\n",
    "\n",
    "# Iterate through the tagged words to categorize verbs by tense\n",
    "for word, tag in pos_tags:\n",
    "    if tag == \"VB\":\n",
    "        infinitive_verbs.append(word)\n",
    "    elif tag == \"VBD\":\n",
    "        past_tense_verbs.append(word)\n",
    "    elif tag == \"VBG\":\n",
    "        present_participle_verbs.append(word)\n",
    "    elif tag == \"VBN\":\n",
    "        past_participle_verbs.append(word)\n",
    "    elif tag == \"VBP\" or tag == \"VBZ\":\n",
    "        present_simple_verbs.append(word)\n",
    "\n",
    "# Print the categorized verbs\n",
    "print(\"Infinitive Verbs:\", infinitive_verbs)\n",
    "print(\"Past Tense Verbs:\", past_tense_verbs)\n",
    "print(\"Present Participle Verbs (Gerunds):\", present_participle_verbs)\n",
    "print(\"Past Participle Verbs:\", past_participle_verbs)\n",
    "print(\"Present Simple Verbs (3rd person singular and present participle):\", present_simple_verbs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
